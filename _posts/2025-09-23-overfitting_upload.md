---
layout: single
title:  "Overfitting"
categories: "AI"
tag: "linear algebra"
toc: true
author_profile: false
sidebar:
    nav: "docs"
---


## 과적합

일반적으로 딥러닝은, 공부랑 같다.  
근데, 공부할 때 연습문제를 통으로 외워버리면, 새로운 유형이 나왔을 떄 대응을 못한다.  
이게 딥러닝에서도 같다.  
모델이 훈련 데이터에만 너무 익숙해진 나머지, 데이터에 포함된 사소한 노이즈나 특정 패턴까지 전부 '암기'해버리는 현상이 발생한다.  
그 결과, 연습문제집(훈련 데이터)에서는 거의 만점에 가까운 성능을 보이지만, 정작 실제 시험(새로운 데이터)에서는 형편없는 점수를 받게 된다.  

이처럼 모델이 훈련 데이터에 과도하게 최적화되어, 새로운 데이터에 대한 일반화 성능이 떨어지는 현상을 **과적합(Overfitting)**이라 한다.  


## 과적합은 왜 발생할까?

**과적합**은 근본적으로 **모델의 표현력(Complexity)이 데이터의 양에 비해 너무 높을 때** 발생한다.  

모델의 목표는 손실 함수 $J(\theta)$를 최소화하는 최적의 파라미터 $\theta$를 찾는 것이다.  
파라미터의 수가 많은 복잡한 모델은 매우 유연한 결정 경계(decision boundary)를 가질 수 있다.  

$$J(\theta) = \frac{1}{m} \sum_{i=1}^{m} \text{Error}(h_\theta(x_i), y_i)$$

이 유연성이 너무 높으면, 모델은 데이터에 내재된 큰 흐름이나 패턴을 학습하는 것을 넘어, 각 데이터 포인트를 하나하나 정확히 통과하기 위해 매우 구불구불한 함수를 만들어낸다.  
즉, 데이터의 '신호(signal)'뿐만 아니라 '잡음(noise)'까지 학습해버리는 것이다.  

결과적으로 훈련 데이터에 대한 손실 값 $J(\theta)$는 0에 가까워지지만, 이 모델은 훈련 데이터의 특수성까지 모두 암기했기 때문에 조금이라도 다른 패턴을 가진 새로운 데이터가 들어오면 제대로 예측하지 못한다.  


이러한 현상은 통계학의 **편향-분산 트레이드오프(Bias-Variance Tradeoff)** 관점에서 설명할 수 있다.  
과적합은 **편향(Bias)은 매우 낮지만 분산(Variance)이 매우 높은 상태**로, 모델이 훈련 데이터의 노이즈에 과도하게 민감하게 반응하는 것을 의미한다.  

## 과정을 증명해보자
### 1. 수학적 모델 설정

증명을 시작하기 전에, 우리가 다루는 데이터와 모델의 관계를 수학적으로 정의해야 한다.

  * **데이터 생성**
    실제 값 $y$는 우리가 알지 못하는 실제 함수 $f(x)$에 평균이 0이고 분산이 $\\sigma^2$인 노이즈 $\\epsilon$이 더해져 생성된다고 가정하자.  

    $$y = f(x) + \epsilon \quad \text{where } E[\epsilon]=0, \text{ Var}(\epsilon)=\sigma^2$$

  * **모델의 예측**
    우리는 훈련 데이터셋 $D$를 사용하여 $f(x)$를 가장 잘 근사하는 모델 $h\_D(x)$를 학습시킨다.  
    여기서 $D$는 모델이 특정 훈련 데이터셋에 의존한다는 것을 명시한다.  
    간결한 표기를 위해 앞으로 $h(x)$로 쓰겠다.

  * **목표**
    우리의 최종 목표는 새로운 데이터 $(x, y)$에 대한 **예측 오차의 기댓값을 최소화**하는 것이다.  
    이 예측 오차는 평균 제곱 오차(MSE)로 측정한다.  

    $$\text{Error} = E[(y - h(x))^2]$$

    여기서 기댓값 $E[\\cdot]$는 가능한 모든 훈련 데이터셋 $D$와 노이즈 $\\epsilon$에 대한 평균을 의미한다.  


### 2. 증명

이제 모델의 예측 오차 $E[(y - h(x))^2]$가 어떻게 구성되는지 분해하여 증명해 보자.  
이 과정은 과적합이 왜 '높은 분산'의 문제인지를 명확하게 보여준다.  

**오차의 전개**

먼저 오차 식에 $f(x)$와 $E[h(x)]$를 더하고 빼서 식을 재구성한다.  
이는 식의 값에 영향을 주지 않는 유용한 수학적 트릭이다.  

$$E[(y - h(x))^2] = E[\{ (y - f(x)) + (f(x) - E[h(x)]) + (E[h(x)] - h(x)) \}^2]$$

여기서 각 항을 편의상 A, B, C로 치환한다.  

  * $A = y - f(x) = \\epsilon$ (줄일 수 없는 오차)
  * $B = f(x) - E[h(x)]$ (편향)
  * $C = E[h(x)] - h(x)$

이제 $(A+B+C)^2 = A^2+B^2+C^2+2AB+2AC+2BC$ 공식을 이용하여 기댓값을 전개한다.  

$$E[A^2+B^2+C^2+2AB+2AC+2BC] = E[A^2] + E[B^2] + E[C^2] + 2E[AB] + 2E[AC] + 2E[BC]$$

**각 항의 기댓값 계산**  

1.  **$E[A^2]$**:
    $E[(y-f(x))^2] = E[\\epsilon^2] = (E[\\epsilon])^2 + Var(\\epsilon) = 0^2 + \\sigma^2 = \\sigma^2$
    이것이 바로 데이터 자체의 노이즈로 인한 줄일 수 없는 오차 (Irreducible Error)이다.  

2.  **$E[B^2]$**:
    $f(x)$와 $E[h(x)]$는 훈련 데이터셋 $D$에 대한 기댓값이므로 상수 취급된다.  
    $E[(f(x) - E[h(x)])^2] = (f(x) - E[h(x)])^2$
    이것은 모델의 평균 예측이 실제 함수에서 얼마나 벗어났는지를 나타내는 편향의 제곱 ($Bias^2$)이다.  

3.  **$E[C^2]$**:
    $E[(E[h(x)] - h(x))^2]$
    이는 모델의 예측값이 평균 예측에서 얼마나 떨어져 있는지를 나타내는 분산의 정의와 정확히 일치한다.  
    $E[(h(x) - E[h(x)])^2] = Var(h(x))$
    이것이 바로 훈련 데이터가 바뀜에 따라 모델이 얼마나 민감하게 변하는지를 나타내는 분산 (Variance)이다.  

4.  **교차 항 (Cross-product terms)**:
    모든 교차 항은 0이 된다.  

      * $E[AB] = E[\\epsilon \\cdot (f(x) - E[h(x)])] = E[\\epsilon](https://www.google.com/search?q=f\(x\)-E%5Bh\(x\)%5D) = 0 \\cdot B = 0$
      * $E[AC] = E[\\epsilon \\cdot (E[h(x)]-h(x))] = E[\\epsilon]E[E[h(x)]-h(x)] = 0$
      * $E[BC] = (https://www.google.com/search?q=f(x)-E%5Bh(x)%5D) E[E[h(x)]-h(x)] = B \\cdot (E[h(x)] - E[h(x)]) = 0$

위 항들을 모두 종합하면, 다음과 같은 최종식을 얻을 수 있다.  

$$E[(y - h(x))^2] = \underbrace{(f(x) - E[h(x)])^2}_{\text{Bias}^2} + \underbrace{E[(h(x) - E[h(x)])^2]}_{\text{Variance}} + \underbrace{\sigma^2}_{\text{Irreducible Error}}$$

이 증명은 **과적합 모델**($Bias^2 \\rightarrow 0$ 이지만 $Variance$가 매우 큰 모델)이 왜 새로운 데이터에 대해 높은 오차를 갖게 되는지를 명확하게 설명한다.  


## 3. 해결책의 수학적 원리: L2 정규화와 가중치 감소

그렇다면 과적합을 막는 **L2 정규화**는 어떻게 높은 분산을 낮추는 것일까?  
이는 경사 하강법의 가중치 업데이트 규칙을 통해 확인할 수 있다.  

L2 정규화가 적용된 손실 함수는 다음과 같다.  
$$J_{reg}(\theta) = J(\theta) + \frac{\lambda}{2m} \sum_{j=1}^{n} \theta_j^2$$

이 손실 함수를 $\\theta\_j$에 대해 편미분하면 다음과 같다.  
$$\frac{\partial J_{reg}}{\partial \theta_j} = \frac{\partial J(\theta)}{\partial \theta_j} + \frac{\lambda}{m} \theta_j$$

경사 하강법의 업데이트 규칙 $\\theta\_j := \\theta\_j - \\alpha \\frac{\\partial J\_{reg}}{\\partial \\theta\_j}$ 에 위 식을 대입하면,
$$\theta_j := \theta_j - \alpha \left( \frac{\partial J(\theta)}{\partial \theta_j} + \frac{\lambda}{m} \theta_j \right)$$

이 식을 $\\theta\_j$에 대해 정리하면.  
$$\theta_j := \theta_j \left( 1 - \alpha \frac{\lambda}{m} \right) - \alpha \frac{\partial J(\theta)}{\partial \theta_j}$$

  * **해석**: 가중치 $\\theta\_j$를 업데이트할 때, 기존의 경사 하강법($\\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta\_j}$)을 적용하기 전에, 먼저 $\\theta\_j$에 $(1 - \\alpha \\frac{\\lambda}{m})$라는 1보다 작은 값을 곱해 가중치의 크기를 줄인다.

이것이 바로 가중치 감소(Weight Decay) 이다.  
L2 정규화는 매 업데이트 스텝마다 가중치를 지속적으로 감소시켜, 가중치가 너무 커지는 것을 막고 모델을 더 단순하게(분산을 낮추게) 만든다.  

## 과적합을 막기 위한 해결책

과적합을 방지하고 모델의 일반화 성능을 높이기 위한 몇 가지 핵심적인 기법이 존재한다.  

#### 1. 정규화 (Regularization)

과적합에 대한 가장 대표적인 해결책 중 하나이다.   
* **원리**: 모델의 복잡도에 페널티를 부과하는 기법이다. 손실 함수 $J(\theta)$에 파라미터(가중치)의 크기에 비례하는 항을 추가하여, 가중치가 너무 큰 값을 갖지 않도록 제한한다. 마치 너무 복잡한 풀이 과정에 감점을 주는 것과 같다.  
* **작동 방식**:  
    * **L2 정규화 (Ridge)**: 손실 함수에 모든 가중치의 제곱 합($||\theta||_2^2$)을 더합니다. 이는 가중치를 전반적으로 작고 고르게 만들어 함수를 부드럽게 만드는 효과가 있다.  
        $$J_{reg}(\theta) = J(\theta) + \lambda \sum_{j=1}^{n} \theta_j^2$$
    * **L1 정규화 (Lasso)**: 손실 함수에 모든 가중치의 절댓값 합($||\theta||_1$)을 더한다. 특정 가중치를 아예 0으로 만들어, 중요하지 않은 특성(feature)을 제거하는 효과가 있다.  
* **효과**: 모델의 복잡도를 제어하여 노이즈보다 데이터의 핵심 패턴에 집중하도록 유도한다.  

#### 2. 데이터 증강 (Data Augmentation)

모델의 일반화 성능을 높이는 가장 근본적인 방법이다.  
* **원리**: 더 많은, 그리고 더 다양한 데이터를 제공하는 것이 과적합을 막는 가장 좋은 방법이다. 데이터가 많아지면 모델이 일부 데이터의 사소한 특징에 얽매이지 않고 전체를 아우르는 패턴을 학습하게 된다.  
* **작동 방식**: 실제 데이터를 구하기 어려울 경우, 기존 데이터를 약간씩 변형하여 데이터의 수를 인위적으로 늘린다. 예를 들어, 이미지 데이터를 좌우로 뒤집거나, 회전시키거나, 일부를 잘라내는 등의 방법이 있다.
* **효과**: 모델이 더 다양한 데이터 패턴에 노출되게 하여 일반화 성능을 향상시킨다.

#### 3. 드롭아웃 (Dropout)
매우 중요 이거 안쓰는 경우가 없다 그냥 꼭 쓴다 생각해라  
신경망의 특정 구조에 과도하게 의존하는 것을 방지하는 기법이다.  
* **원리**: 훈련 과정에서 신경망의 일부 뉴런을 확률적으로 비활성화(제거)하는 기법입니다.  
* **작동 방식**: 마치 매번 다른 팀원 조합으로 문제를 푸는 것과 같다. 특정 뉴런에 의존할 수 없게 되므로, 네트워크는 더 강건하고 중복된 표현(representation)을 학습하게 된다.  
* **효과**: 모델이 여러 개의 작은 신경망을 앙상블하는 것과 유사한 효과를 내어 과적합을 효과적으로 억제한다.  


## 결론

**과적합**은 모델이 훈련 데이터라는 연습문제집을 완벽히 암기하여 실전에서 힘을 쓰지 못하는 문제이다.  
이는 모델의 복잡도가 데이터에 비해 너무 높을 때 발생하며, **정규화**를 통해 복잡도에 페널티를 주고, **데이터 증강**으로 더 많은 경험을 시켜주며, **드롭아웃**으로 특정 방식에만 의존하지 않도록 훈련시키는 것이 중요하다.  

이러한 기법들을 통해 모델의 일반화 성능을 확보하는 것은, 안정적인 인공지능 모델을 만들기 위한 필수적인 과정이라 할 수 있다.  
