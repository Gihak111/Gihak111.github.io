---
layout: single
title:  "가벼운 트랜스 포머 모델 만들기"
categories: "pynb"
tag: "code"
toc: true
author_profile: false
sidebar:
    nav: "docs"
---

# 일반적인 bert 모델의 크기는 무겁다
이는 모바일 환경에서 운용하기 까다롭게 한다.  
그냥 만들면 700MB가 넘어가 버리는 Bert 모델을 가겹게 만들어 모바일에 탑제 하려면 어떻게 해야 할까?  
이럴 경우에는 다음과 같은 해결책을 얻을 수 있다.  

BERT 모델을 크기를 최소화하면서 성능을 유지하려면, 모델 아키텍처와 하이퍼파라미터 조정이 중요하다.  
일반적으로 BERT는 크기가 큰 모델이지만, 모바일 환경에서도 사용할 수 있도록 최적화된 버전을 만들 수 있다.  

1. **모델 크기 줄이기 전략**:  
   - **BERT의 작은 변형**: BERT의 변형 모델 중에 크기가 작고 성능이 뛰어난 모델들이 있다. 예를 들어, DistilBERT는 BERT의 파라미터를 절반으로 줄이면서 성능을 유지한다. 이를 사용하면 모델 크기를 크게 줄일 수 있다.  
   - **MobileBERT**: MobileBERT는 모바일 환경을 위해 최적화된 BERT 변형으로, 원본 BERT 대비 훨씬 가벼우며 성능 저하는 최소화된다.
   - **Quantization**: 모델 양자화를 통해 파라미터 크기를 줄일 수 있다. 32비트 부동소수점을 8비트 정수로 변환해 모델 크기를 줄이는 방식이다. 이는 약간의 성능 저하가 있을 수 있지만, 크기를 크게 줄일 수 있다.  

2. **은닉층과 노드 수 조정**:  
   - 은닉층의 수와 각 층의 노드 수는 모델의 성능과 크기에 직접적으로 영향을 미친다. 일반적으로 BERT Base는 12개의 Transformer 레이어와 768차원의 히든 사이즈를 가지고 있지만, 이를 더 작은 값으로 줄일 수 있다. 예를 들어, 6개의 레이어와 512차원의 히든 사이즈로도 성능을 유지할 수 있으며, 이 경우 모델 크기도 훨씬 작아진다. 물론, AI의 성능은 떨어지게 된다.  
   
3. **최적화 예시**:  
   - **DistilBERT**: 66M 파라미터, 약 240MB.  
   - **TinyBERT**: 약 14.5M 파라미터, 약 60MB.  
   - **MobileBERT**: 약 25M 파라미터, 약 100MB.  

결론적으로, 은닉층과 노드를 적절히 줄이고 DistilBERT, MobileBERT 같은 경량화된 BERT 모델을 활용하면 500MB 이하의 모델 크기로도 충분히 앱을 만들 수 있다.  