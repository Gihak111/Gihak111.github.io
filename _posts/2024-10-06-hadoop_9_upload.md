---
layout: single
title:  "하둡 강좌 9편  HDFS 데이터 복제"
categories: "hadoop"
tag: "code"
toc: true
author_profile: false
sidebar:
    nav: "docs"
---

### 하둡 강좌 9편: **HDFS 데이터 복제와 신뢰성 관리**  
이번 강좌에서는 **HDFS (Hadoop Distributed File System)**에서 데이터를 어떻게 복제하고, 이를 통해 시스템의 신뢰성을 관리하는지에 대해 다루겠다.  
HDFS는 대규모 데이터를 처리하기 위해 설계되었으며, 데이터 복제를 통해 장애 상황에서도 데이터를 안정적으로 제공할 수 있다.  

## 1. HDFS의 데이터 복제 개념  
HDFS의 핵심 개념 중 하나는 **데이터 복제(Replication)**이다.  
HDFS는 데이터를 여러 블록으로 나누어 저장하며, 각 블록은 여러 노드에 복제되어 저장된다.  
기본적으로 HDFS는 하나의 블록을 세 개의 노드에 복제하는데, 이를 통해 데이터 손실에 대비하고 데이터 접근 속도를 향상시킬 수 있다.  

### 1.1 복제 개수(Replication Factor)  
HDFS의 **복제 개수**는 각 블록이 몇 개의 복사본으로 저장될지를 결정한다.  
기본값은 3으로, 데이터의 신뢰성을 위해 각 블록이 세 개의 복사본으로 분산 저장된다.  
복제 개수는 설정 파일이나 명령어를 통해 변경할 수 있다.  

### 1.2 복제 전략  
HDFS는 데이터를 **랙 인식(Rack Awareness)** 기반으로 복제한다.  
이는 각 데이터 블록을 서로 다른 랙(rack)에 있는 노드에 복제하여, 랙 단위의 장애가 발생하더라도 데이터를 복구할 수 있도록 한다.  

## 2. 데이터 복제 설정  
### 2.1 복제 개수 설정  
HDFS에서 파일의 복제 개수는 **HDFS 설정 파일**이나 명령어를 통해 조정할 수 있다.  

#### 2.1.1 설정 파일에서 복제 개수 설정  
HDFS의 기본 복제 개수는 `hdfs-site.xml` 파일에서 설정된다.  
```xml
<property>
  <name>dfs.replication</name>
  <value>3</value>
</property>
```  
여기서 `dfs.replication` 속성의 값을 변경하면 전체 클러스터에서 기본 복제 개수가 변경된다.  

#### 2.1.2 명령어로 복제 개수 변경  
개별 파일에 대해서 복제 개수를 변경할 수도 있다.  
HDFS 명령어를 사용하여 복제 개수를 설정할 수 있다.  
```bash
hdfs dfs -setrep -w 2 /user/hadoop/example.txt
```  
위 명령어는 **example.txt** 파일의 복제 개수를 2로 변경한다.  

### 2.2 복제 상태 확인  
복제 상태는 `fsck` 명령어로 확인할 수 있다.  
```bash
hdfs fsck /user/hadoop/example.txt -files -blocks -racks
```  
이 명령어는 파일의 블록, 복제 상태, 저장된 랙 정보를 확인하는 데 사용된다.  

## 3. 데이터 복제의 중요성  
HDFS에서 복제는 데이터 신뢰성과 가용성을 보장하는 데 핵심적인 역할을 한다.  

### 3.1 장애 허용과 복구  
HDFS는 노드의 장애를 대비하여 데이터를 여러 곳에 복제한다.  
하나의 데이터 노드가 장애를 일으키더라도, 다른 노드에 저장된 복제본을 통해 데이터를 복구할 수 있다.  

#### 3.1.1 노드 장애 시 데이터 복구  
데이터 노드가 장애를 일으키면, 이름 노드(NameNode)는 자동으로 다른 노드에 데이터 복제본을 생성하여 복구를 시작한다.  
이를 통해 HDFS는 자동으로 복제 상태를 유지하고 데이터 손실을 방지한다.  

### 3.2 데이터 접근 속도 향상  
복제된 데이터는 장애 복구 외에도 **데이터 접근 속도**를 향상시킨다.  
HDFS는 클라이언트가 요청한 데이터를 가장 가까운 노드에 저장된 복제본에서 읽을 수 있도록 하여 네트워크 대역폭을 절약하고 읽기 성능을 향상시킨다.  

## 4. 복제 관리 도구  
HDFS에서는 데이터 복제를 관리하고 모니터링할 수 있는 다양한 도구를 제공한다.  

### 4.1 HDFS Balancer  
HDFS Balancer는 클러스터에서 데이터가 고르게 분산되지 않았을 때 데이터 블록을 재배치하여 균형을 맞추는 도구이다.  
데이터 노드 간의 저장 공간을 고르게 분배하여 데이터 접근 성능을 향상시킬 수 있다.  
```bash
hdfs balancer
```  
이 명령어는 HDFS Balancer를 실행하여 클러스터의 데이터 블록을 재분배한다.  

### 4.2 HDFS Rebalancer  
Rebalancer는 저장 공간이 부족한 데이터 노드에서 사용하지 않은 노드로 데이터를 이동시킨다.  
이를 통해 클러스터 전체의 자원 효율성을 높일 수 있다.  

## 5. 실습: 복제 개수 조정과 데이터 복구  
### 5.1 실습 환경 설정  
먼저, 파일을 업로드하여 HDFS에서 복제 개수를 변경하고 상태를 확인하는 실습을 진행하겠다.  

  1. 파일 업로드  
  ```bash
  hdfs dfs -put localfile.txt /user/hadoop/example.txt
  ```

  2. 복제 개수 변경  
  ```bash
  hdfs dfs -setrep -w 4 /user/hadoop/example.txt
  ```

  3. 복제 상태 확인  
  ```bash
  hdfs fsck /user/hadoop/example.txt -files -blocks -racks
  ```

  4. 파일 삭제 및 복구  
  ```bash
  hdfs dfs -rm /user/hadoop/example.txt
  ```

파일을 삭제 후 다시 업로드하고 복제 상태를 모니터링한다.  

---

## 6. 마무리  
이번 강좌에서는 HDFS에서 **데이터 복제**를 통해 데이터를 신뢰성 있게 관리하고, 이를 실습을 통해 확인하는 방법을 배웠다. HDFS의 복제 전략은 대규모 데이터 처리를 위한 신뢰성을 제공하며, 장애 상황에서도 데이터를 안정적으로 복구할 수 있도록 돕는다. 다음 강좌에서는 **HDFS의 데이터 압축**을 다루며, 대규모 데이터를 효율적으로 저장하는 방법을 배워보겠다.  